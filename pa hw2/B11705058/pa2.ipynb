{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRTM programming assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "doc_term_freqs = []\n",
    "df = {}\n",
    "\n",
    "stop_words = [\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', \n",
    "    'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', \n",
    "    'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', \n",
    "    'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', \n",
    "    'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', \n",
    "    'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', \n",
    "    'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', \n",
    "    'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', \n",
    "    'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', \n",
    "    'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \n",
    "    'should', 'now'\n",
    "]\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_letters(content):\n",
    "    return ''.join([char if char.isalpha() else ' ' for char in content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 1096):\n",
    "    filename = f'./data/{i}.txt'\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        \n",
    "    content = remove_non_letters(content)\n",
    "        \n",
    "    tokens = content.split()\n",
    "    \n",
    "    tokens = [stemmer.stem(word.lower()) for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    documents.append(tokens)\n",
    "    \n",
    "    term_freq = {}\n",
    "    for token in tokens:\n",
    "        term_freq[token] = term_freq.get(token, 0) + 1\n",
    "    doc_term_freqs.append(term_freq)\n",
    "    \n",
    "    unique_tokens = set(tokens)\n",
    "    for token in unique_tokens:\n",
    "        df[token] = df.get(token, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(documents)\n",
    "\n",
    "idf = {}\n",
    "for term, freq in df.items():\n",
    "    idf[term] = math.log10(N / freq)\n",
    "\n",
    "vocabulary = sorted(idf.keys())\n",
    "term_index = {term: idx for idx, term in enumerate(vocabulary)}\n",
    "\n",
    "tf_idf_matrix = np.zeros((N, len(vocabulary)))\n",
    "\n",
    "for doc_idx, term_freq in enumerate(doc_term_freqs):\n",
    "    for term, freq in term_freq.items():\n",
    "        if term in term_index:\n",
    "            idx = term_index[term]\n",
    "            tf_idf_matrix[doc_idx, idx] = freq * idf[term]\n",
    "\n",
    "tf_idf_norm = np.linalg.norm(tf_idf_matrix, axis=1, keepdims=True)\n",
    "tf_idf_norm[tf_idf_norm == 0] = 1\n",
    "tf_idf_matrix = tf_idf_matrix / tf_idf_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/dictionary.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write('t_index\\tterm\\tdf\\n')\n",
    "    for index, term in enumerate(vocabulary, start=1):\n",
    "        file.write(f'{index}\\t{term}\\t{df[term]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_number = 1\n",
    "vector = tf_idf_matrix[document_number - 1]\n",
    "output_filename = f'./output/{document_number}.txt'\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    for idx, value in enumerate(vector, start=1):\n",
    "        if value != 0:\n",
    "            f.write(f'{idx}\\t{value:.6f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(Docx, Docy):\n",
    "    Docx_index = Docx - 1\n",
    "    Docy_index = Docy - 1\n",
    "    \n",
    "    vector_x = tf_idf_matrix[Docx_index]\n",
    "    vector_y = tf_idf_matrix[Docy_index]\n",
    "    \n",
    "    return np.dot(vector_x, vector_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048482080659025026\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine(1, 1095)\n",
    "print(similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
