{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 讀取 training.txt \n",
    "def load_training_data(training_file):\n",
    "    docs = []\n",
    "    labels = []\n",
    "    train_doc_ids = set()\n",
    "    with open(training_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])  # 類別 ID\n",
    "            doc_ids = map(int, parts[1:])  # 該類別的文檔 ID\n",
    "            train_doc_ids.update(doc_ids)  # 將文檔 ID 加入集合\n",
    "            for doc_id in doc_ids:\n",
    "                docs.append(str(doc_id))  # 將文檔 ID 視為文字\n",
    "                labels.append(class_id)\n",
    "    return docs, labels, train_doc_ids\n",
    "\n",
    "\n",
    "\n",
    "#讀取 test 資料\n",
    "def load_test_data(test_folder):\n",
    "    docs = []\n",
    "    doc_ids = []\n",
    "    for file_name in sorted(os.listdir(test_folder), key=lambda x: int(x.split(\".\")[0])):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            doc_id = int(file_name.split(\".\")[0])\n",
    "            file_path = os.path.join(test_folder, file_name)\n",
    "            with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "                content = file.read().strip()\n",
    "                docs.append(content)\n",
    "                doc_ids.append(doc_id)\n",
    "    return docs, doc_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 計算 TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_df(docs):\n",
    "    tf_list = []\n",
    "    df = defaultdict(int)\n",
    "    for doc in docs:\n",
    "        terms = doc.split()\n",
    "        tf = Counter(terms)\n",
    "        tf_list.append(tf)\n",
    "        for term in tf.keys():\n",
    "            df[term] += 1\n",
    "    return tf_list, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Chi-Square 特徵選擇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_selection(docs, labels, df, num_features=500):\n",
    "    class_term_count = defaultdict(lambda: defaultdict(int))\n",
    "    class_doc_count = defaultdict(int)\n",
    "    total_docs = len(docs)\n",
    "\n",
    "    # 統計每個類別中的詞頻\n",
    "    for doc, label in zip(docs, labels):\n",
    "        terms = set(doc.split())\n",
    "        class_doc_count[label] += 1\n",
    "        for term in terms:\n",
    "            class_term_count[label][term] += 1\n",
    "\n",
    "    # 計算 Chi-Square 分數\n",
    "    chi_scores = defaultdict(float)\n",
    "    for term in df.keys():\n",
    "        for class_id in class_doc_count.keys():\n",
    "            A = class_term_count[class_id][term]\n",
    "            B = sum(class_term_count[c][term] for c in class_doc_count if c != class_id)\n",
    "            C = class_doc_count[class_id] - A\n",
    "            D = total_docs - (A + B + C)\n",
    "\n",
    "            numerator = total_docs * (A * D - B * C) ** 2\n",
    "            denominator = (A + C) * (B + D) * (A + B) * (C + D)\n",
    "            if denominator > 0:\n",
    "                chi_scores[term] += numerator / denominator\n",
    "\n",
    "    # 選擇最高分的詞\n",
    "    selected_features = sorted(chi_scores, key=chi_scores.get, reverse=True)[:num_features]\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 訓練 Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(docs, labels, selected_features):\n",
    "    class_term_count = defaultdict(lambda: defaultdict(int))\n",
    "    class_doc_count = defaultdict(int)\n",
    "    vocab_size = len(selected_features)\n",
    "    total_docs = len(docs)\n",
    "\n",
    "    # 計算每個類別的詞頻與文檔數\n",
    "    for doc, label in zip(docs, labels):\n",
    "        terms = doc.split()\n",
    "        class_doc_count[label] += 1\n",
    "        for term in terms:\n",
    "            if term in selected_features:\n",
    "                class_term_count[label][term] += 1\n",
    "\n",
    "    # 計算條件機率與先驗機率\n",
    "    class_priors = {c: count / total_docs for c, count in class_doc_count.items()}\n",
    "    class_word_probs = defaultdict(dict)\n",
    "    for class_id, term_count in class_term_count.items():\n",
    "        total_terms = sum(term_count.values())\n",
    "        for term in selected_features:\n",
    "            class_word_probs[class_id][term] = (term_count[term] + 1) / (total_terms + vocab_size)\n",
    "\n",
    "    return class_priors, class_word_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 測試 Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_naive_bayes(docs, class_priors, class_word_probs, selected_features):\n",
    "    predictions = []\n",
    "    for doc in docs:\n",
    "        terms = doc.split()\n",
    "        class_scores = {}\n",
    "        for class_id, prior in class_priors.items():\n",
    "            score = math.log(prior)\n",
    "            for term in terms:\n",
    "                if term in selected_features:\n",
    "                    score += math.log(class_word_probs[class_id].get(term, 1 / (len(selected_features) + 1)))\n",
    "            class_scores[class_id] = score\n",
    "        if class_scores:\n",
    "            predictions.append(max(class_scores, key=class_scores.get))\n",
    "        else:\n",
    "            # 若無法計算分數，則預設為類別 1（或其他邏輯）\n",
    "            predictions.append(1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 設定路徑\n",
    "    training_file = \"train_docs/training.txt\"\n",
    "    test_folder = \"test_docs\"\n",
    "\n",
    "    # 1. 載入訓練資料與測試資料\n",
    "    train_docs, train_labels, train_doc_ids = load_training_data(training_file)\n",
    "    test_docs, test_doc_ids = load_test_data(test_folder)\n",
    "\n",
    "    # **排除已經出現在 training.txt 的文檔**\n",
    "    filtered_test_docs = []\n",
    "    filtered_test_doc_ids = []\n",
    "    for doc, doc_id in zip(test_docs, test_doc_ids):\n",
    "        if doc_id not in train_doc_ids:  # 如果文檔 ID 不在訓練數據中\n",
    "            filtered_test_docs.append(doc)\n",
    "            filtered_test_doc_ids.append(doc_id)\n",
    "\n",
    "    # 2. 計算詞頻與特徵選擇\n",
    "    tf_list, df = compute_tf_df(train_docs)\n",
    "    selected_features = chi_square_selection(train_docs, train_labels, df)\n",
    "\n",
    "    # 3. 訓練模型\n",
    "    class_priors, class_word_probs = train_naive_bayes(train_docs, train_labels, selected_features)\n",
    "\n",
    "    # 4. 測試模型\n",
    "    predictions = predict_naive_bayes(filtered_test_docs, class_priors, class_word_probs, selected_features)\n",
    "\n",
    "    # 5. 輸出結果\n",
    "    with open(\"submission.csv\", \"w\") as f:\n",
    "        f.write(\"doc_id,class_id\\n\")\n",
    "        for doc_id, pred in zip(filtered_test_doc_ids, predictions):\n",
    "            f.write(f\"{doc_id},{pred}\\n\")\n",
    "    print(\"Results saved to submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
